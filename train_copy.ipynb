{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from CRFmodel import CRFModel\n",
    "\n",
    "speaker_vocab_dict_path = 'vocabs/speaker_vocab.pkl'\n",
    "emotion_vocab_dict_path = 'vocabs/emotion_vocab.pkl'\n",
    "sentiment_vocab_dict_path = 'vocabs/sentiment_vocab.pkl'\n",
    "\n",
    "\n",
    "def pad_to_len(list_data, max_len, pad_value):\n",
    "    list_data = list_data[-max_len:]\n",
    "    len_to_pad = max_len-len(list_data)\n",
    "    pads = [pad_value] * len_to_pad\n",
    "    list_data.extend(pads)\n",
    "    return list_data\n",
    "\n",
    "\n",
    "def get_vocabs(file_paths, addi_file_path):\n",
    "    speaker_vocab = vocab.UnkVocab()\n",
    "    emotion_vocab = vocab.Vocab()\n",
    "    sentiment_vocab = vocab.Vocab()\n",
    "    # 保证neutral 在第0类\n",
    "    emotion_vocab.word2index('neutral', train=True)\n",
    "    # global speaker_vocab, emotion_vocab\n",
    "    for file_path in file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        for row in tqdm(data.iterrows(), desc='get vocab from {}'.format(file_path)):\n",
    "            meta = row[1]\n",
    "            emotion = meta['Emotion'].lower()\n",
    "            emotion_vocab.word2index(emotion, train=True)\n",
    "    additional_data = json.load(open(addi_file_path, 'r'))\n",
    "    for episode_id in additional_data:\n",
    "        for scene in additional_data.get(episode_id):\n",
    "            for utterance in scene['utterances']:\n",
    "                speaker = utterance['speakers'][0].lower()\n",
    "                speaker_vocab.word2index(speaker, train=True)\n",
    "    speaker_vocab = speaker_vocab.prune_by_count(1000)\n",
    "    speakers = list(speaker_vocab.counts.keys())\n",
    "    speaker_vocab = vocab.UnkVocab()\n",
    "    for speaker in speakers:\n",
    "        speaker_vocab.word2index(speaker, train=True)\n",
    "\n",
    "    logging.info('total {} speakers'.format(len(speaker_vocab.counts.keys())))\n",
    "    torch.save(emotion_vocab.to_dict(), emotion_vocab_dict_path)\n",
    "    torch.save(speaker_vocab.to_dict(), speaker_vocab_dict_path)\n",
    "    torch.save(sentiment_vocab.to_dict(), sentiment_vocab_dict_path)\n",
    "\n",
    "def load_emorynlp_and_builddataset(file_path, train=False):\n",
    "    speaker_vocab = vocab.UnkVocab.from_dict(torch.load(\n",
    "        speaker_vocab_dict_path\n",
    "    ))\n",
    "    emotion_vocab = vocab.Vocab.from_dict(torch.load(\n",
    "        emotion_vocab_dict_path\n",
    "    ))\n",
    "    data = pd.read_csv(file_path)\n",
    "    ret_utterances = []\n",
    "    ret_speaker_ids = []\n",
    "    ret_emotion_idxs = []\n",
    "    utterances = []\n",
    "    full_contexts = []\n",
    "    speaker_ids = []\n",
    "    emotion_idxs = []\n",
    "    sentiment_idxs = []\n",
    "    pre_dial_id = -1\n",
    "    max_turns = 0\n",
    "    for row in tqdm(data.iterrows(), desc='processing file {}'.format(file_path)):\n",
    "        meta = row[1]\n",
    "        utterance = meta['Utterance'].lower().replace(\n",
    "            '’', '\\'').replace(\"\\\"\", '')\n",
    "        speaker = meta['Speaker'].lower()\n",
    "        utterance = speaker + ' says:, ' + utterance\n",
    "        emotion = meta['Emotion'].lower()\n",
    "        dialogue_id = meta['Scene_ID']\n",
    "        utterance_id = meta['Utterance_ID']\n",
    "        if pre_dial_id == -1:\n",
    "            pre_dial_id = dialogue_id\n",
    "        if dialogue_id != pre_dial_id:\n",
    "            ret_utterances.append(full_contexts)\n",
    "            ret_speaker_ids.append(speaker_ids)\n",
    "            ret_emotion_idxs.append(emotion_idxs)\n",
    "            max_turns = max(max_turns, len(utterances))\n",
    "            utterances = []\n",
    "            full_contexts = []\n",
    "            speaker_ids = []\n",
    "            emotion_idxs = []\n",
    "        pre_dial_id = dialogue_id\n",
    "        speaker_id = speaker_vocab.word2index(speaker)\n",
    "        emotion_idx = emotion_vocab.word2index(emotion)\n",
    "        token_ids = tokenizer(utterance, add_special_tokens=False)[\n",
    "            'input_ids'] + [CONFIG['SEP']]\n",
    "        full_context = []\n",
    "        if len(utterances) > 0:\n",
    "            context = utterances[-3:]\n",
    "            for pre_uttr in context:\n",
    "                full_context += pre_uttr\n",
    "        full_context += token_ids\n",
    "        # query\n",
    "        query = speaker + ' feels <mask>'\n",
    "        query_ids = [CONFIG['SEP']] + tokenizer(query, add_special_tokens=False)['input_ids'] + [CONFIG['SEP']]\n",
    "        full_context += query_ids\n",
    "\n",
    "        full_context = pad_to_len(\n",
    "            full_context, CONFIG['max_len'], CONFIG['pad_value'])\n",
    "        # + CONFIG['shift']\n",
    "        utterances.append(token_ids)\n",
    "        full_contexts.append(full_context)\n",
    "        speaker_ids.append(speaker_id)\n",
    "        emotion_idxs.append(emotion_idx)\n",
    "\n",
    "    pad_utterance = [CONFIG['SEP']] + tokenizer(\n",
    "        \"1\",\n",
    "        add_special_tokens=False\n",
    "    )['input_ids'] + [CONFIG['SEP']]\n",
    "    pad_utterance = pad_to_len(\n",
    "        pad_utterance, CONFIG['max_len'], CONFIG['pad_value'])\n",
    "    # for CRF\n",
    "    ret_mask = []\n",
    "    ret_last_turns = []\n",
    "    for dial_id, utterances in tqdm(enumerate(ret_utterances), desc='build dataset'):\n",
    "        mask = [1] * len(utterances)\n",
    "        while len(utterances) < max_turns:\n",
    "            utterances.append(pad_utterance)\n",
    "            ret_emotion_idxs[dial_id].append(-1)\n",
    "            ret_speaker_ids[dial_id].append(0)\n",
    "            mask.append(0)\n",
    "        ret_mask.append(mask)\n",
    "        ret_utterances[dial_id] = utterances\n",
    "\n",
    "        last_turns = [-1] * max_turns\n",
    "        for turn_id in range(max_turns):\n",
    "            curr_spk = ret_speaker_ids[dial_id][turn_id]\n",
    "            if curr_spk == 0:\n",
    "                break\n",
    "            for idx in range(0, turn_id):\n",
    "                if curr_spk == ret_speaker_ids[dial_id][idx]:\n",
    "                    last_turns[turn_id] = idx\n",
    "        ret_last_turns.append(last_turns)\n",
    "    dataset = TensorDataset(\n",
    "        torch.LongTensor(ret_utterances),\n",
    "        torch.LongTensor(ret_speaker_ids),\n",
    "        torch.LongTensor(ret_emotion_idxs),\n",
    "        torch.ByteTensor(ret_mask),\n",
    "        torch.LongTensor(ret_last_turns)\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_meld_and_builddataset(file_path, train=False):\n",
    "    speaker_vocab = vocab.UnkVocab.from_dict(torch.load(\n",
    "        speaker_vocab_dict_path\n",
    "    ))\n",
    "    emotion_vocab = vocab.Vocab.from_dict(torch.load(\n",
    "        emotion_vocab_dict_path\n",
    "    ))\n",
    "\n",
    "    data = pd.read_csv(file_path)\n",
    "    ret_utterances = []\n",
    "    ret_speaker_ids = []\n",
    "    ret_emotion_idxs = []\n",
    "    utterances = []\n",
    "    full_contexts = []\n",
    "    speaker_ids = []\n",
    "    emotion_idxs = []\n",
    "    pre_dial_id = -1\n",
    "    max_turns = 0\n",
    "    for row in tqdm(data.iterrows(), desc='processing file {}'.format(file_path)):\n",
    "        meta = row[1]\n",
    "        utterance = meta['Utterance'].replace(\n",
    "            '’', '\\'').replace(\"\\\"\", '')\n",
    "        speaker = meta['Speaker']\n",
    "        utterance = speaker + ' says:, ' + utterance\n",
    "        emotion = meta['Emotion'].lower()\n",
    "        dialogue_id = meta['Dialogue_ID']\n",
    "        utterance_id = meta['Utterance_ID']\n",
    "        if pre_dial_id == -1:\n",
    "            pre_dial_id = dialogue_id\n",
    "        if dialogue_id != pre_dial_id:\n",
    "            ret_utterances.append(full_contexts)\n",
    "            ret_speaker_ids.append(speaker_ids)\n",
    "            ret_emotion_idxs.append(emotion_idxs)\n",
    "            max_turns = max(max_turns, len(utterances))\n",
    "            utterances = []\n",
    "            full_contexts = []\n",
    "            speaker_ids = []\n",
    "            emotion_idxs = []\n",
    "        pre_dial_id = dialogue_id\n",
    "        speaker_id = speaker_vocab.word2index(speaker)\n",
    "        emotion_idx = emotion_vocab.word2index(emotion)\n",
    "        token_ids = tokenizer(utterance, add_special_tokens=False)[\n",
    "            'input_ids'] + [CONFIG['SEP']]\n",
    "        full_context = []\n",
    "        if len(utterances) > 0:\n",
    "            context = utterances[-3:]\n",
    "            for pre_uttr in context:\n",
    "                full_context += pre_uttr\n",
    "        full_context += token_ids\n",
    "        # query\n",
    "        query = 'Now ' + speaker + ' feels <mask>'\n",
    "        query_ids = tokenizer(query, add_special_tokens=False)['input_ids'] + [CONFIG['SEP']]\n",
    "        full_context += query_ids\n",
    "\n",
    "        full_context = pad_to_len(\n",
    "            full_context, CONFIG['max_len'], CONFIG['pad_value'])\n",
    "        # + CONFIG['shift']\n",
    "        utterances.append(token_ids)\n",
    "        full_contexts.append(full_context)\n",
    "        speaker_ids.append(speaker_id)\n",
    "        emotion_idxs.append(emotion_idx)\n",
    "\n",
    "    pad_utterance = [CONFIG['SEP']] + tokenizer(\n",
    "        \"1\",\n",
    "        add_special_tokens=False\n",
    "    )['input_ids'] + [CONFIG['SEP']]\n",
    "    pad_utterance = pad_to_len(\n",
    "        pad_utterance, CONFIG['max_len'], CONFIG['pad_value'])\n",
    "    # for CRF\n",
    "    ret_mask = []\n",
    "    ret_last_turns = []\n",
    "    for dial_id, utterances in tqdm(enumerate(ret_utterances), desc='build dataset'):\n",
    "        mask = [1] * len(utterances)\n",
    "        while len(utterances) < max_turns:\n",
    "            utterances.append(pad_utterance)\n",
    "            ret_emotion_idxs[dial_id].append(-1)\n",
    "            ret_speaker_ids[dial_id].append(0)\n",
    "            mask.append(0)\n",
    "        ret_mask.append(mask)\n",
    "        ret_utterances[dial_id] = utterances\n",
    "\n",
    "        last_turns = [-1] * max_turns\n",
    "        for turn_id in range(max_turns):\n",
    "            curr_spk = ret_speaker_ids[dial_id][turn_id]\n",
    "            if curr_spk == 0:\n",
    "                break\n",
    "            for idx in range(0, turn_id):\n",
    "                if curr_spk == ret_speaker_ids[dial_id][idx]:\n",
    "                    last_turns[turn_id] = idx\n",
    "        ret_last_turns.append(last_turns)\n",
    "    dataset = TensorDataset(\n",
    "        torch.LongTensor(ret_utterances),\n",
    "        torch.LongTensor(ret_speaker_ids),\n",
    "        torch.LongTensor(ret_emotion_idxs),\n",
    "        torch.ByteTensor(ret_mask),\n",
    "        torch.LongTensor(ret_last_turns)\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def get_paramsgroup(model, warmup=False):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    pre_train_lr = CONFIG['ptmlr']\n",
    "    '''\n",
    "    frozen_params = []\n",
    "    frozen_layers = [3,4,5,6,7,8]\n",
    "    for layer_idx in frozen_layers:\n",
    "        frozen_params.extend(\n",
    "            list(map(id, model.context_encoder.encoder.layer[layer_idx].parameters()))\n",
    "        )\n",
    "    '''\n",
    "    bert_params = list(map(id, model.encoder.parameters()))\n",
    "    crf_params = list(map(id, model.CRFlayer.parameters()))\n",
    "    params = []\n",
    "    warmup_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        # if id(param) in frozen_params:\n",
    "        #     continue\n",
    "        lr = CONFIG['lr']\n",
    "        weight_decay = 0\n",
    "        if id(param) in bert_params:\n",
    "            lr = pre_train_lr\n",
    "        if id(param) in crf_params:\n",
    "            lr = CONFIG['lr'] * 10\n",
    "        if not any(nd in name for nd in no_decay):\n",
    "            weight_decay = 0\n",
    "        params.append(\n",
    "            {\n",
    "                'params': param,\n",
    "                'lr': lr,\n",
    "                'weight_decay': weight_decay\n",
    "            }\n",
    "        )\n",
    "        # warmup的时候不考虑bert\n",
    "        warmup_params.append(\n",
    "            {\n",
    "                'params': param,\n",
    "                'lr': 0 if id(param) in bert_params else lr,\n",
    "                'weight_decay': weight_decay\n",
    "            }\n",
    "        )\n",
    "    if warmup:\n",
    "        return warmup_params\n",
    "    params = sorted(params, key=lambda x: x['lr'], reverse=True)\n",
    "    return params\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, data, epoch_num=0, max_step=-1):\n",
    "\n",
    "    loss_func = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    sampler = RandomSampler(data)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        sampler=sampler,\n",
    "        num_workers=0  # multiprocessing.cpu_count()\n",
    "    )\n",
    "    tq_train = tqdm(total=len(dataloader), position=1)\n",
    "    accumulation_steps = CONFIG['accumulation_steps']\n",
    "\n",
    "    for batch_id, batch_data in enumerate(dataloader):\n",
    "        batch_data = [x.to(model.device()) for x in batch_data]\n",
    "        sentences = batch_data[0]\n",
    "        speaker_ids = batch_data[1]\n",
    "        emotion_idxs = batch_data[2]\n",
    "        mask = batch_data[3]\n",
    "        last_turns = batch_data[4]\n",
    "        outputs = model(sentences, mask, speaker_ids, last_turns, emotion_idxs)\n",
    "        loss = outputs\n",
    "        # loss += loss_func(outputs[3], sentiment_idxs)\n",
    "        tq_train.set_description('loss is {:.2f}'.format(loss.item()))\n",
    "        tq_train.update()\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "        if batch_id % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # torch.cuda.empty_cache()\n",
    "    tq_train.close()\n",
    "\n",
    "\n",
    "def test(model, data):\n",
    "\n",
    "    pred_list = []\n",
    "    hidden_pred_list = []\n",
    "    selection_list = []\n",
    "    y_true_list = []\n",
    "    model.eval()\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        sampler=sampler,\n",
    "        num_workers=0,  # multiprocessing.cpu_count()\n",
    "    )\n",
    "    tq_test = tqdm(total=len(dataloader), desc=\"testing\", position=2)\n",
    "    for batch_id, batch_data in enumerate(dataloader):\n",
    "        batch_data = [x.to(model.device()) for x in batch_data]\n",
    "        sentences = batch_data[0]\n",
    "        speaker_ids = batch_data[1]\n",
    "        emotion_idxs = batch_data[2].cpu().numpy().tolist()\n",
    "        mask = batch_data[3]\n",
    "        last_turns = batch_data[4]\n",
    "        outputs = model(sentences, mask, speaker_ids, last_turns, None)\n",
    "        for batch_idx in range(mask.shape[0]):\n",
    "            for seq_idx in range(mask.shape[1]):\n",
    "                if mask[batch_idx][seq_idx]:\n",
    "                    print(\"Output: \", outputs)\n",
    "                    print(\"Batch: \", batch_idx)\n",
    "                    print(\"Seq: \", seq_idx)\n",
    "                    pred_list.append(outputs[batch_idx][seq_idx])\n",
    "                    y_true_list.append(emotion_idxs[batch_idx][seq_idx])\n",
    "        tq_test.update()\n",
    "    F1 = f1_score(y_true=y_true_list, y_pred=pred_list, average='weighted')\n",
    "    model.train()\n",
    "    return F1\n",
    "\n",
    "\n",
    "def train(model, train_data_path, dev_data_path, test_data_path):\n",
    "    if CONFIG['task_name'] == 'meld':\n",
    "        devset = load_meld_and_builddataset(dev_data_path)\n",
    "        testset = load_meld_and_builddataset(test_data_path)\n",
    "        trainset = load_meld_and_builddataset(train_data_path)\n",
    "    else:\n",
    "        devset = load_emorynlp_and_builddataset(dev_data_path)\n",
    "        testset = load_emorynlp_and_builddataset(test_data_path)\n",
    "        trainset = load_emorynlp_and_builddataset(train_data_path)\n",
    "\n",
    "\n",
    "    # warmup\n",
    "    optimizer = torch.optim.AdamW(get_paramsgroup(model, warmup=True))\n",
    "    for epoch in range(CONFIG['wp']):\n",
    "        train_epoch(model, optimizer, trainset, epoch_num=epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        f1 = test(model, devset)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('f1 on dev @ warmup epoch {} is {:.4f}'.format(\n",
    "            epoch, f1), flush=True)\n",
    "    # train\n",
    "    optimizer = torch.optim.AdamW(get_paramsgroup(model))\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=1, gamma=0.9)\n",
    "    best_f1 = -1\n",
    "    tq_epoch = tqdm(total=CONFIG['epochs'], position=0)\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        tq_epoch.set_description('training on epoch {}'.format(epoch))\n",
    "        tq_epoch.update()\n",
    "        train_epoch(model, optimizer, trainset, epoch_num=epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        f1 = test(model, devset)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('f1 on dev @ epoch {} is {:.4f}'.format(epoch, f1), flush=True)\n",
    "        # '''\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model,\n",
    "                       'models/f1_{:.4f}_@epoch{}.pkl'\n",
    "                       .format(best_f1, epoch))\n",
    "        if lr_scheduler.get_last_lr()[0] > 1e-5:\n",
    "            lr_scheduler.step()\n",
    "        f1 = test(model, testset)\n",
    "        print('f1 on test @ epoch {} is {:.4f}'.format(epoch, f1), flush=True)\n",
    "        # f1 = test(model, test_on_trainset)\n",
    "        # print('f1 on train @ epoch {} is {:.4f}'.format(epoch, f1), flush=True)\n",
    "        # '''\n",
    "    tq_epoch.close()\n",
    "    lst = os.listdir('./models')\n",
    "    lst = list(filter(lambda item: item.endswith('.pkl'), lst))\n",
    "    lst.sort(key=lambda x: os.path.getmtime(os.path.join('models', x)))\n",
    "    model = torch.load(os.path.join('models', lst[-1]))\n",
    "    f1 = test(model, testset)\n",
    "    print('best f1 on test is {:.4f}'.format(f1), flush=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-te', '--test', action='store_true',\n",
    "                        help='run test', default=False)\n",
    "    parser.add_argument('-tr', '--train', action='store_true',\n",
    "                        help='run train', default=False)\n",
    "    parser.add_argument('-ft', '--finetune', action='store_true',\n",
    "                        help='fine tune base the best model', default=False)\n",
    "    parser.add_argument('-pr', '--print_error', action='store_true',\n",
    "                        help='print error case', default=False)\n",
    "    parser.add_argument('-bsz', '--batch', help='Batch_size',\n",
    "                        required=False, default=CONFIG['batch_size'], type=int)\n",
    "    parser.add_argument('-epochs', '--epochs', help='epochs',\n",
    "                        required=False, default=CONFIG['epochs'], type=int)\n",
    "    parser.add_argument('-lr', '--lr', help='learning rate',\n",
    "                        required=False, default=CONFIG['lr'], type=float)\n",
    "    parser.add_argument('-p_unk', '--p_unk', help='prob to generate unk speaker',\n",
    "                        required=False, default=CONFIG['p_unk'], type=float)\n",
    "    parser.add_argument('-ptmlr', '--ptm_lr', help='ptm learning rate',\n",
    "                        required=False, default=CONFIG['ptmlr'], type=float)\n",
    "    parser.add_argument('-tsk', '--task_name', default='meld', type=str)\n",
    "    parser.add_argument('-fp16', '--fp_16', action='store_true',\n",
    "                        help='use fp 16', default=False)\n",
    "    parser.add_argument('-wp', '--warm_up', default=CONFIG['wp'],\n",
    "                        type=int, required=False)\n",
    "    parser.add_argument('-dpt', '--dropout', default=CONFIG['dropout'],\n",
    "                        type=float, required=False)\n",
    "    parser.add_argument('-e_stop', '--eval_stop',\n",
    "                        default=500, type=int, required=False)\n",
    "    parser.add_argument('-bert_path', '--bert_path',\n",
    "                        default=CONFIG['bert_path'], type=str, required=False)\n",
    "    parser.add_argument('-data_path', '--data_path',\n",
    "                        default=CONFIG['data_path'], type=str, required=False)\n",
    "    parser.add_argument('-acc_step', '--accumulation_steps',\n",
    "                        default=CONFIG['accumulation_steps'], type=int, required=False)\n",
    "\n",
    "    # read the arguments from commandline\n",
    "    args = parser.parse_args()\n",
    "    CONFIG['data_path'] = args.data_path\n",
    "    CONFIG['lr'] = args.lr\n",
    "    CONFIG['ptmlr'] = args.ptm_lr\n",
    "    CONFIG['epochs'] = args.epochs\n",
    "    CONFIG['bert_path'] = args.bert_path\n",
    "    CONFIG['batch_size'] = args.batch\n",
    "    CONFIG['dropout'] = args.dropout\n",
    "    CONFIG['wp'] = args.warm_up\n",
    "    CONFIG['p_unk'] = args.p_unk\n",
    "    CONFIG['accumulation_steps'] = args.accumulation_steps\n",
    "    CONFIG['task_name'] = args.task_name\n",
    "    train_data_path = os.path.join(CONFIG['data_path'], 'train_sent_emo.csv')\n",
    "    test_data_path = os.path.join(CONFIG['data_path'], 'test_sent_emo.csv')\n",
    "    dev_data_path = os.path.join(CONFIG['data_path'], 'dev_sent_emo.csv')\n",
    "    if args.task_name =='emorynlp':\n",
    "        train_data_path = os.path.join(CONFIG['data_path'], 'emorynlp_train_final.csv')\n",
    "        test_data_path = os.path.join(CONFIG['data_path'], 'emorynlp_test_final.csv')\n",
    "        dev_data_path = os.path.join(CONFIG['data_path'], 'emorynlp_dev_final.csv')\n",
    "    os.makedirs('vocabs', exist_ok=True)\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    seed = 1024\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    get_vocabs([train_data_path, dev_data_path, test_data_path],\n",
    "               'friends_transcript.json')\n",
    "    # model = PortraitModel(CONFIG)\n",
    "    model = CRFModel(numClasses=7, dropout=0.3, bert_path='roberta-base')\n",
    "    device = CONFIG['device']\n",
    "    model.to(device)\n",
    "    print('---config---')\n",
    "    for k, v in CONFIG.items():\n",
    "        print(k, '\\t\\t\\t', v, flush=True)\n",
    "    if args.finetune:\n",
    "        lst = os.listdir('./models')\n",
    "        lst = list(filter(lambda item: item.endswith('.pkl'), lst))\n",
    "        lst.sort(key=lambda x: os.path.getmtime(os.path.join('models', x)))\n",
    "        model = torch.load(os.path.join('models', lst[-1]))\n",
    "        print('checkpoint {} is loaded'.format(\n",
    "            os.path.join('models', lst[-1])), flush=True)\n",
    "    if args.train:\n",
    "        train(model, train_data_path, dev_data_path, test_data_path)\n",
    "    if args.test:\n",
    "        # testset = load_meld_and_builddataset(dev_data_path)\n",
    "        if args.task_name =='emorynlp':\n",
    "            testset = load_emorynlp_and_builddataset(test_data_path)\n",
    "        if args.task_name == 'meld':\n",
    "            testset = load_meld_and_builddataset(test_data_path)\n",
    "        best_f1 = test(model, testset)\n",
    "        print(best_f1)\n",
    "\n",
    "\n",
    "# implementation\n",
    "# data processing, forward function, train function, results \n",
    "# experiments ran so far\n",
    "# report f1 score based on different epochs, different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not yet tested\n",
    "def train(model, train_data_path, dev_data_path, test_data_path):\n",
    "    devset = load_meld_and_builddataset(dev_data_path)\n",
    "    testset = load_meld_and_builddataset(test_data_path)\n",
    "    trainset = load_meld_and_builddataset(train_data_path)\n",
    "\n",
    "\n",
    "    # warmup\n",
    "    optimizer = torch.optim.AdamW(get_paramsgroup(model, warmup=True))\n",
    "    for epoch in range(CONFIG['wp']):\n",
    "        train_epoch(model, optimizer, trainset, epoch_num=epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        f1 = test(model, devset)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('f1 on dev @ warmup epoch {} is {:.4f}'.format(\n",
    "            epoch, f1), flush=True)\n",
    "\n",
    "    # train\n",
    "    optimizer = torch.optim.AdamW(get_paramsgroup(model))\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=1, gamma=0.9)\n",
    "    best_f1 = -1\n",
    "    tq_epoch = tqdm(total=CONFIG['epochs'], position=0)\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        tq_epoch.set_description('training on epoch {}'.format(epoch))\n",
    "        tq_epoch.update()\n",
    "        train_epoch(model, optimizer, trainset, epoch_num=epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        f1 = test(model, devset)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('f1 on dev @ epoch {} is {:.4f}'.format(epoch, f1), flush=True)\n",
    "        # '''\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model,\n",
    "                       'models/f1_{:.4f}_@epoch{}.pkl'\n",
    "                       .format(best_f1, epoch))\n",
    "        if lr_scheduler.get_last_lr()[0] > 1e-5:\n",
    "            lr_scheduler.step()\n",
    "        f1 = test(model, testset)\n",
    "        print('f1 on test @ epoch {} is {:.4f}'.format(epoch, f1), flush=True)\n",
    "        # f1 = test(model, test_on_trainset)\n",
    "        # print('f1 on train @ epoch {} is {:.4f}'.format(epoch, f1), flush=True)\n",
    "        # '''\n",
    "    tq_epoch.close()\n",
    "    lst = os.listdir('./models')\n",
    "    lst = list(filter(lambda item: item.endswith('.pkl'), lst))\n",
    "    lst.sort(key=lambda x: os.path.getmtime(os.path.join('models', x)))\n",
    "    model = torch.load(os.path.join('models', lst[-1]))\n",
    "    f1 = test(model, testset)\n",
    "    print('best f1 on test is {:.4f}'.format(f1), flush=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('-te', '--test', action='store_true',\n",
    "                        help='run test', default=False)\n",
    "    parser.add_argument('-tr', '--train', action='store_true',\n",
    "                        help='run train', default=False)\n",
    "    parser.add_argument('-ft', '--finetune', action='store_true',\n",
    "                        help='fine tune base the best model', default=False)\n",
    "    parser.add_argument('-pr', '--print_error', action='store_true',\n",
    "                        help='print error case', default=False)\n",
    "    parser.add_argument('-bsz', '--batch', help='Batch_size',\n",
    "                        required=False, default=CONFIG['batch_size'], type=int)\n",
    "    parser.add_argument('-epochs', '--epochs', help='epochs',\n",
    "                        required=False, default=CONFIG['epochs'], type=int)\n",
    "    parser.add_argument('-lr', '--lr', help='learning rate',\n",
    "                        required=False, default=CONFIG['lr'], type=float)\n",
    "    parser.add_argument('-p_unk', '--p_unk', help='prob to generate unk speaker',\n",
    "                        required=False, default=CONFIG['p_unk'], type=float)\n",
    "    parser.add_argument('-ptmlr', '--ptm_lr', help='ptm learning rate',\n",
    "                        required=False, default=CONFIG['ptmlr'], type=float)\n",
    "    parser.add_argument('-tsk', '--task_name', default='meld', type=str)\n",
    "    parser.add_argument('-fp16', '--fp_16', action='store_true',\n",
    "                        help='use fp 16', default=False)\n",
    "    parser.add_argument('-wp', '--warm_up', default=CONFIG['wp'],\n",
    "                        type=int, required=False)\n",
    "    parser.add_argument('-dpt', '--dropout', default=CONFIG['dropout'],\n",
    "                        type=float, required=False)\n",
    "    parser.add_argument('-e_stop', '--eval_stop',\n",
    "                        default=500, type=int, required=False)\n",
    "    parser.add_argument('-bert_path', '--bert_path',\n",
    "                        default=CONFIG['bert_path'], type=str, required=False)\n",
    "    parser.add_argument('-data_path', '--data_path',\n",
    "                        default=CONFIG['data_path'], type=str, required=False)\n",
    "    parser.add_argument('-acc_step', '--accumulation_steps',\n",
    "                        default=CONFIG['accumulation_steps'], type=int, required=False)\n",
    "\n",
    "    # read the arguments from commandline\n",
    "    args = parser.parse_args()\n",
    "    CONFIG['data_path'] = args.data_path\n",
    "    CONFIG['lr'] = args.lr\n",
    "    CONFIG['ptmlr'] = args.ptm_lr\n",
    "    CONFIG['epochs'] = args.epochs\n",
    "    CONFIG['bert_path'] = args.bert_path\n",
    "    CONFIG['batch_size'] = args.batch\n",
    "    CONFIG['dropout'] = args.dropout\n",
    "    CONFIG['wp'] = args.warm_up\n",
    "    CONFIG['p_unk'] = args.p_unk\n",
    "    CONFIG['accumulation_steps'] = args.accumulation_steps\n",
    "    CONFIG['task_name'] = args.task_name\n",
    "    train_data_path = os.path.join(CONFIG['data_path'], 'train_sent_emo.csv')\n",
    "    test_data_path = os.path.join(CONFIG['data_path'], 'test_sent_emo.csv')\n",
    "    dev_data_path = os.path.join(CONFIG['data_path'], 'dev_sent_emo.csv')\n",
    "    if args.task_name =='emorynlp':\n",
    "        train_data_path = os.path.join(CONFIG['data_path'], 'emorynlp_train_final.csv')\n",
    "        test_data_path = os.path.join(CONFIG['data_path'], 'emorynlp_test_final.csv')\n",
    "        dev_data_path = os.path.join(CONFIG['data_path'], 'emorynlp_dev_final.csv')\n",
    "    os.makedirs('vocabs', exist_ok=True)\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    seed = 1024\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    get_vocabs([train_data_path, dev_data_path, test_data_path],\n",
    "               'friends_transcript.json')\n",
    "    # model = PortraitModel(CONFIG)\n",
    "    model = CRFModel(numClasses=7, dropout=0.3, bert_path='roberta-base')\n",
    "    device = CONFIG['device']\n",
    "    model.to(device)\n",
    "    print('---config---')\n",
    "    for k, v in CONFIG.items():\n",
    "        print(k, '\\t\\t\\t', v, flush=True)\n",
    "    if args.finetune:\n",
    "        lst = os.listdir('./models')\n",
    "        lst = list(filter(lambda item: item.endswith('.pkl'), lst))\n",
    "        lst.sort(key=lambda x: os.path.getmtime(os.path.join('models', x)))\n",
    "        model = torch.load(os.path.join('models', lst[-1]))\n",
    "        print('checkpoint {} is loaded'.format(\n",
    "            os.path.join('models', lst[-1])), flush=True)\n",
    "    if args.train:\n",
    "        train(model, train_data_path, dev_data_path, test_data_path)\n",
    "    if args.test:\n",
    "        # testset = load_meld_and_builddataset(dev_data_path)\n",
    "        if args.task_name =='emorynlp':\n",
    "            testset = load_emorynlp_and_builddataset(test_data_path)\n",
    "        if args.task_name == 'meld':\n",
    "            testset = load_meld_and_builddataset(test_data_path)\n",
    "        best_f1 = test(model, testset)\n",
    "        print(best_f1)\n",
    "\n",
    "# test reference\n",
    "def get_paramsgroup(model, warmup=False):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    pre_train_lr = CONFIG['ptmlr']\n",
    "    '''\n",
    "    frozen_params = []\n",
    "    frozen_layers = [3,4,5,6,7,8]\n",
    "    for layer_idx in frozen_layers:\n",
    "        frozen_params.extend(\n",
    "            list(map(id, model.context_encoder.encoder.layer[layer_idx].parameters()))\n",
    "        )\n",
    "    '''\n",
    "    bert_params = list(map(id, model.encoder.parameters()))\n",
    "    crf_params = list(map(id, model.CRFlayer.parameters()))\n",
    "    params = []\n",
    "    warmup_params = []\n",
    "    for name, param in model.named_parameters():\n",
    "        # if id(param) in frozen_params:\n",
    "        #     continue\n",
    "        lr = CONFIG['lr']\n",
    "        weight_decay = 0\n",
    "        if id(param) in bert_params:\n",
    "            lr = pre_train_lr\n",
    "        if id(param) in crf_params:\n",
    "            lr = CONFIG['lr'] * 10\n",
    "        if not any(nd in name for nd in no_decay):\n",
    "            weight_decay = 0\n",
    "        params.append(\n",
    "            {\n",
    "                'params': param,\n",
    "                'lr': lr,\n",
    "                'weight_decay': weight_decay\n",
    "            }\n",
    "        )\n",
    "        # warmup的时候不考虑bert\n",
    "        warmup_params.append(\n",
    "            {\n",
    "                'params': param,\n",
    "                'lr': 0 if id(param) in bert_params else lr,\n",
    "                'weight_decay': weight_decay\n",
    "            }\n",
    "        )\n",
    "    if warmup:\n",
    "        return warmup_params\n",
    "    params = sorted(params, key=lambda x: x['lr'], reverse=True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dev_f1 = [0.5784, 0.6048, 0.6030, 0.6161, 0.6268]\n",
    "test_f1 = [0.6194, 0.6466, 0.6250, 0.6445, 0.6527]\n",
    "epoch = np.arange(1,6,1)\n",
    "plt.grid(axis = 'y', linewidth = 0.3)\n",
    "plt.plot(epoch, test_f1, label='test_f1')\n",
    "plt.plot(epoch, dev_f1, label='dev_f1')\n",
    "\n",
    "plt.xticks(epoch)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('RoBERTa-Base F1 Score')\n",
    "\n",
    "plt.savefig('RoBERTa-Base.jpg', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from CRFmodel import CRFModel\n",
    "import itertools\n",
    "\n",
    "# 창현 버전\n",
    "# works\n",
    "def train_epoch(model, optimizer, data, epoch_num=0, max_step=-1):\n",
    "\n",
    "    loss_func = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    dataloader = DataLoader(data, batch_size=CONFIG['batch_size'], sampler=RandomSampler(data), num_workers=0)\n",
    "\n",
    "    for batch in dataloader:\n",
    "        for i in range(len(batch)):\n",
    "            if i == 0:\n",
    "                sentences = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==1:\n",
    "                speaker_ids = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==2:\n",
    "                emotion_idxs = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==3:\n",
    "                mask = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==4:\n",
    "                last_turns = batch[i].to(model.device())\n",
    "                continue\n",
    "        loss = model(sentences, mask, speaker_ids, last_turns, emotion_idxs)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "# not yet tested\n",
    "def test(model, data):\n",
    "\n",
    "    yPred = []\n",
    "    yTrue = []\n",
    "    model.eval()\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, batch_size=CONFIG['batch_size'], sampler=sampler, num_workers=0)\n",
    "#    tq_test = tqdm(total=len(dataloader), desc=\"testing\", position=2)\n",
    "    # for batch_id, batch_data in enumerate(dataloader):\n",
    "    #     batch_data = [x.to(model.device()) for x in batch_data]\n",
    "    #     sentences = batch_data[0]\n",
    "    #     speaker_ids = batch_data[1]\n",
    "    #     emotion_idxs = batch_data[2].cpu().numpy().tolist()\n",
    "    #     mask = batch_data[3]\n",
    "    #     last_turns = batch_data[4]\n",
    "    #     outputs = model(sentences, mask, speaker_ids, last_turns, None)\n",
    "    for batch in dataloader:\n",
    "        for i in range(len(batch)):\n",
    "            if i == 0:\n",
    "                sentences = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==1:\n",
    "                speaker_ids = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==2:\n",
    "                emotion_idxs = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==3:\n",
    "                mask = batch[i].to(model.device())\n",
    "                continue\n",
    "            elif i==4:\n",
    "                last_turns = batch[i].to(model.device())\n",
    "                continue\n",
    "        out = model(sentences, mask, speaker_ids, last_turns, None)\n",
    "\n",
    "        maskBatch = torch.arange(0, mask.shape[0])\n",
    "        maskSequence = torch.arange(0, mask.shape[1])\n",
    "        \n",
    "        for batch1, sequence1 in torch.cartesian_prod(maskBatch, maskSequence):\n",
    "            # Only if not padded (aka. there is information) -> mask==1 (True), APPEND\n",
    "            if bool(mask[batch1][sequence1]) != True: \n",
    "                continue\n",
    "            else:\n",
    "                # print(\"Output: \", outputs)\n",
    "                # print(\"Batch: \", batch_idx)\n",
    "                # print(\"Seq: \", seq_idx)\n",
    "                yPred.append(out[batch1][sequence1])\n",
    "                yTrue.append(emotion_idxs[batch1][sequence1])\n",
    "#        tq_test.update()\n",
    "    score = f1_score(y_pred=yPred, y_true=yTrue, average='weighted')\n",
    "    model.train()\n",
    "    return score\n",
    "\n",
    "# too many indices for tensor of dimension 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.arange(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data):\n",
    "\n",
    "    pred_list = []\n",
    "    hidden_pred_list = []\n",
    "    selection_list = []\n",
    "    y_true_list = []\n",
    "    model.eval()\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        sampler=sampler,\n",
    "        num_workers=0,  # multiprocessing.cpu_count()\n",
    "    )\n",
    "    tq_test = tqdm(total=len(dataloader), desc=\"testing\", position=2)\n",
    "    for batch_id, batch_data in enumerate(dataloader):\n",
    "        batch_data = [x.to(model.device()) for x in batch_data]\n",
    "        sentences = batch_data[0]\n",
    "        speaker_ids = batch_data[1]\n",
    "        emotion_idxs = batch_data[2].cpu().numpy().tolist()\n",
    "        mask = batch_data[3]\n",
    "        last_turns = batch_data[4]\n",
    "        outputs = model(sentences, mask, speaker_ids, last_turns, None)\n",
    "        for batch_idx in range(mask.shape[0]):\n",
    "            for seq_idx in range(mask.shape[1]):\n",
    "                if mask[batch_idx][seq_idx]:\n",
    "                    print(\"Output: \", outputs)\n",
    "                    print(\"Batch: \", batch_idx)\n",
    "                    print(\"Seq: \", seq_idx)\n",
    "                    pred_list.append(outputs[batch_idx][seq_idx])\n",
    "                    y_true_list.append(emotion_idxs[batch_idx][seq_idx])\n",
    "        tq_test.update()\n",
    "    F1 = f1_score(y_true=y_true_list, y_pred=pred_list, average='weighted')\n",
    "    model.train()\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, data, epoch_num=0, max_step=-1):\n",
    "\n",
    "    loss_func = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    sampler = RandomSampler(data)\n",
    "    dataloader = DataLoader(\n",
    "        data,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        sampler=sampler,\n",
    "        num_workers=0  # multiprocessing.cpu_count()\n",
    "    )\n",
    "    tq_train = tqdm(total=len(dataloader), position=1)\n",
    "    accumulation_steps = CONFIG['accumulation_steps']\n",
    "\n",
    "    for batch_id, batch_data in enumerate(dataloader):\n",
    "        batch_data = [x.to(model.device()) for x in batch_data]\n",
    "        sentences = batch_data[0]\n",
    "        speaker_ids = batch_data[1]\n",
    "        emotion_idxs = batch_data[2]\n",
    "        mask = batch_data[3]\n",
    "        last_turns = batch_data[4]\n",
    "        outputs = model(sentences, mask, speaker_ids, last_turns, emotion_idxs)\n",
    "        loss = outputs\n",
    "        # loss += loss_func(outputs[3], sentiment_idxs)\n",
    "        tq_train.set_description('loss is {:.2f}'.format(loss.item()))\n",
    "        tq_train.update()\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "        if batch_id % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # torch.cuda.empty_cache()\n",
    "    tq_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = 0\n",
    "if hi:\n",
    "    print(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a96337b70dab0eb2bcaed0ba38f8b8a9f8193ff32d1d954b22771c4e1a3afc5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
